{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import models_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading csv data file\n",
    "data = pd.read_csv('behavioural_data\\\\filtered_anlz_group\\\\\\group_outside.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> columns of rt, stimulus, subj_idx, coherency, spatial are mandatary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>condition</th>\n",
       "      <th>image_index</th>\n",
       "      <th>response</th>\n",
       "      <th>response_corr</th>\n",
       "      <th>rt</th>\n",
       "      <th>stimulus</th>\n",
       "      <th>subj_idx</th>\n",
       "      <th>coherency</th>\n",
       "      <th>spatial</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.529206</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>High</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.519501</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>High</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.611204</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>High</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.465089</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>High</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.367166</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>High</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4499</th>\n",
       "      <td>3</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.309091</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>Low</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4500</th>\n",
       "      <td>3</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.261170</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>Low</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4501</th>\n",
       "      <td>3</td>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.271483</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>Low</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4502</th>\n",
       "      <td>4</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.283706</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>Low</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4503</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.296490</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>High</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4504 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      condition  image_index  response  response_corr        rt  stimulus  \\\n",
       "0             1           19         1              1  0.529206         1   \n",
       "1             2           12         0              1  0.519501         0   \n",
       "2             2           20         1              1  0.611204         1   \n",
       "3             1            5         0              1  0.465089         0   \n",
       "4             1           13         0              1  0.367166         0   \n",
       "...         ...          ...       ...            ...       ...       ...   \n",
       "4499          3           41         0              1  0.309091         0   \n",
       "4500          3           45         0              1  0.261170         0   \n",
       "4501          3           63         0              0  0.271483         1   \n",
       "4502          4           40         0              1  0.283706         0   \n",
       "4503          1            2         0              1  0.296490         0   \n",
       "\n",
       "      subj_idx coherency spatial  \n",
       "0            1      High     Yes  \n",
       "1            1      High      No  \n",
       "2            1      High      No  \n",
       "3            1      High     Yes  \n",
       "4            1      High     Yes  \n",
       "...        ...       ...     ...  \n",
       "4499        17       Low     Yes  \n",
       "4500        17       Low     Yes  \n",
       "4501        17       Low     Yes  \n",
       "4502        17       Low      No  \n",
       "4503        17      High     Yes  \n",
       "\n",
       "[4504 rows x 9 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run modelp\n",
    "models_utils.run_modelp(data)\n",
    "#run modelt\n",
    "models_utils.run_modelt(data)\n",
    "#run modez\n",
    "models_utils.run_modelz(data)\n",
    "#run modea\n",
    "models_utils.run_modela(data)\n",
    "#run modev\n",
    "models_utils.run_modelv(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Therefore, for each model, there are a db model file and a csv file includes estimated parameters "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> In order to compute R-sqaure for RT and Acc, the csv file related to modelt is laoded.\n",
    "> Then, you can generate data for group level. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#modelt_1.csv\n",
    "filename = 'modelt.csv'\n",
    "modelt_excel = pd.read_csv(filename)\n",
    "#simulate data for group ourside\n",
    "\n",
    "simulated = hddm.generate.gen_rand_data(params={'High_Yes_1':  {'v': modelt_excel['v(High.1)'][0], 'v_std':  modelt_excel['v_std'][0], 'a':modelt_excel['a'][0], 'a_std':modelt_excel['a_std'][0],  't':modelt_excel['t(Yes)'][0], 't_std':modelt_excel['t_std'][0], 'z':modelt_excel['z'][0], 'z_std':modelt_excel['z_std'][0], 'st':modelt_excel['st'][0]},\n",
    "                                                'High_Yes_0':  {'v': modelt_excel['v(High.0)'][0], 'v_std':  modelt_excel['v_std'][0], 'a':modelt_excel['a'][0], 'a_std':modelt_excel['a_std'][0],  't':modelt_excel['t(Yes)'][0], 't_std':modelt_excel['t_std'][0], 'z':modelt_excel['z'][0], 'z_std':modelt_excel['z_std'][0], 'st':modelt_excel['st'][0]},\n",
    "                                                'High_No_1' :  {'v': modelt_excel['v(High.1)'][0], 'v_std':  modelt_excel['v_std'][0], 'a':modelt_excel['a'][0], 'a_std':modelt_excel['a_std'][0],  't':modelt_excel['t(No)'][0] , 't_std':modelt_excel['t_std'][0], 'z':modelt_excel['z'][0], 'z_std':modelt_excel['z_std'][0], 'st':modelt_excel['st'][0]},\n",
    "                                                'High_No_0' :  {'v': modelt_excel['v(High.0)'][0], 'v_std':  modelt_excel['v_std'][0], 'a':modelt_excel['a'][0], 'a_std':modelt_excel['a_std'][0],  't':modelt_excel['t(No)'][0] , 't_std':modelt_excel['t_std'][0], 'z':modelt_excel['z'][0], 'z_std':modelt_excel['z_std'][0], 'st':modelt_excel['st'][0]},\n",
    "                                                'Low_Yes_1' :  {'v': modelt_excel['v(Low.1)'][0],  'v_std':  modelt_excel['v_std'][0], 'a':modelt_excel['a'][0], 'a_std':modelt_excel['a_std'][0],  't':modelt_excel['t(Yes)'][0], 't_std':modelt_excel['t_std'][0], 'z':modelt_excel['z'][0], 'z_std':modelt_excel['z_std'][0], 'st':modelt_excel['st'][0]},\n",
    "                                                'Low_Yes_0' :  {'v': modelt_excel['v(Low.0)'][0],  'v_std':  modelt_excel['v_std'][0], 'a':modelt_excel['a'][0], 'a_std':modelt_excel['a_std'][0],  't':modelt_excel['t(Yes)'][0], 't_std':modelt_excel['t_std'][0], 'z':modelt_excel['z'][0], 'z_std':modelt_excel['z_std'][0], 'st':modelt_excel['st'][0]},\n",
    "                                                'Low_No_1'  :  {'v': modelt_excel['v(Low.1)'][0],  'v_std':  modelt_excel['v_std'][0], 'a':modelt_excel['a'][0], 'a_std':modelt_excel['a_std'][0],  't':modelt_excel['t(No)'][0] , 't_std':modelt_excel['t_std'][0], 'z':modelt_excel['z'][0], 'z_std':modelt_excel['z_std'][0], 'st':modelt_excel['st'][0]},\n",
    "                                                'Low_No_0'  :  {'v': modelt_excel['v(Low.0)'][0],  'v_std':  modelt_excel['v_std'][0], 'a':modelt_excel['a'][0], 'a_std':modelt_excel['a_std'][0],  't':modelt_excel['t(No)'][0] , 't_std':modelt_excel['t_std'][0], 'z':modelt_excel['z'][0], 'z_std':modelt_excel['z_std'][0], 'st':modelt_excel['st'][0]}},size=100000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simulated_data       = simulated[0]\n",
    "simulated_High_Yes_1 = simulated_data[simulated_data['condition']=='High_Yes_1']\n",
    "simulated_High_Yes_0 = simulated_data[simulated_data['condition']=='High_Yes_0']\n",
    "simulated_High_No_1  = simulated_data[simulated_data['condition']=='High_No_1']\n",
    "simulated_High_No_0  = simulated_data[simulated_data['condition']=='High_No_0']\n",
    "simulated_Low_Yes_1  = simulated_data[simulated_data['condition']=='Low_Yes_1']\n",
    "simulated_Low_Yes_0  = simulated_data[simulated_data['condition']=='Low_Yes_0']\n",
    "simulated_Low_No_1   = simulated_data[simulated_data['condition']=='Low_No_1']\n",
    "simulated_Low_No_0   = simulated_data[simulated_data['condition']=='Low_No_0']\n",
    "\n",
    "#mean rt for condition\n",
    "simulated_rt_High_Yes_1_mean = np.mean(simulated_High_Yes_1['rt'])\n",
    "simulated_rt_High_Yes_0_mean = np.mean(simulated_High_Yes_0['rt'])\n",
    "simulated_rt_High_No_1_mean  = np.mean(simulated_High_No_1['rt'])\n",
    "simulated_rt_High_No_0_mean  = np.mean(simulated_High_No_0['rt'])\n",
    "simulated_rt_Low_Yes_1_mean  = np.mean(simulated_Low_Yes_1['rt'])\n",
    "simulated_rt_Low_Yes_0_mean  = np.mean(simulated_Low_Yes_0['rt'])\n",
    "simulated_rt_Low_No_1_mean   = np.mean(simulated_Low_No_1['rt'])\n",
    "simulated_rt_Low_No_0_mean   = np.mean(simulated_Low_No_0['rt'])\n",
    "\n",
    "#mean acc for condition\n",
    "simulated_acc_High_Yes_1_mean = float(np.sum(simulated_High_Yes_1['response']==1))/len(simulated_High_Yes_1)\n",
    "simulated_acc_High_Yes_0_mean = float(np.sum(simulated_High_Yes_0['response']==0))/len(simulated_High_Yes_0)\n",
    "simulated_acc_High_No_1_mean  = float(np.sum(simulated_High_No_1['response']==1))/len(simulated_High_No_1)\n",
    "simulated_acc_High_No_0_mean  = float(np.sum(simulated_High_No_0['response']==0))/len(simulated_High_No_0)\n",
    "simulated_acc_Low_Yes_1_mean  = float(np.sum(simulated_Low_Yes_1['response']==1))/len(simulated_Low_Yes_1)\n",
    "simulated_acc_Low_Yes_0_mean  = float(np.sum(simulated_Low_Yes_0['response']==0))/len(simulated_Low_Yes_0)\n",
    "simulated_acc_Low_No_1_mean   = float(np.sum(simulated_Low_No_1['response']==1))/len(simulated_Low_No_1)\n",
    "simulated_acc_Low_No_0_mean   = float(np.sum(simulated_Low_No_0['response']==0))/len(simulated_Low_No_0)\n",
    "\n",
    "\n",
    "#array mean rt\n",
    "simulated_rt_cons_mean = np.array([simulated_rt_High_Yes_1_mean,\n",
    "                                     simulated_rt_High_Yes_0_mean,\n",
    "                                     simulated_rt_High_No_1_mean,\n",
    "                                     simulated_rt_High_No_0_mean,\n",
    "                                     simulated_rt_Low_Yes_1_mean,\n",
    "                                     simulated_rt_Low_Yes_0_mean,\n",
    "                                     simulated_rt_Low_No_1_mean,\n",
    "                                     simulated_rt_Low_No_0_mean]) \n",
    "\n",
    "#array mean acc\n",
    "simulated_acc_cons_mean = np.array([simulated_acc_High_Yes_1_mean,\n",
    "                                     simulated_acc_High_Yes_0_mean,\n",
    "                                     simulated_acc_High_No_1_mean,\n",
    "                                     simulated_acc_High_No_0_mean,\n",
    "                                     simulated_acc_Low_Yes_1_mean,\n",
    "                                     simulated_acc_Low_Yes_0_mean,\n",
    "                                     simulated_acc_Low_No_1_mean,\n",
    "                                     simulated_acc_Low_No_0_mean]) \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#data for condition\n",
    "data_High_Yes_1 = data[(data['coherency']=='High')&(data['spatial']=='Yes')&(data['stimulus']==1)]\n",
    "data_High_Yes_0 = data[(data['coherency']=='High')&(data['spatial']=='Yes')&(data['stimulus']==0)]\n",
    "data_High_No_1  = data[(data['coherency']=='High')&(data['spatial']=='No')&(data['stimulus'] ==1)]\n",
    "data_High_No_0  = data[(data['coherency']=='High')&(data['spatial']=='No')&(data['stimulus'] ==0)]\n",
    "data_Low_Yes_1  = data[(data['coherency']=='Low')&(data['spatial'] =='Yes')&(data['stimulus']==1)]\n",
    "data_Low_Yes_0  = data[(data['coherency']=='Low')&(data['spatial'] =='Yes')&(data['stimulus']==0)]\n",
    "data_Low_No_1   = data[(data['coherency']=='Low')&(data['spatial'] =='No')&(data['stimulus'] ==1)]\n",
    "data_Low_No_0   = data[(data['coherency']=='Low')&(data['spatial'] =='No')&(data['stimulus'] ==0)]\n",
    " \n",
    "    \n",
    "#mean rt of condition for data \n",
    "data_rt_High_Yes_1_mean = np.mean(data_High_Yes_1['rt'])\n",
    "data_rt_High_Yes_0_mean = np.mean(data_High_Yes_0['rt']) \n",
    "data_rt_High_No_1_mean  = np.mean(data_High_No_1['rt'])\n",
    "data_rt_High_No_0_mean  = np.mean(data_High_No_0['rt']) \n",
    "data_rt_Low_Yes_1_mean  = np.mean(data_Low_Yes_1['rt']) \n",
    "data_rt_Low_Yes_0_mean  = np.mean(data_Low_Yes_0['rt'])\n",
    "data_rt_Low_No_1_mean   = np.mean(data_Low_No_1['rt'])\n",
    "data_rt_Low_No_0_mean   = np.mean(data_Low_No_0['rt'])\n",
    "\n",
    "\n",
    "#mean acc of condition for data \n",
    "data_acc_High_Yes_1_mean = float(np.sum(data_High_Yes_1['response']==1))/len(data_High_Yes_1)\n",
    "data_acc_High_Yes_0_mean = float(np.sum(data_High_Yes_0['response']==0))/len(data_High_Yes_0)\n",
    "data_acc_High_No_1_mean  = float(np.sum(data_High_No_1['response']==1))/len(data_High_No_1)\n",
    "data_acc_High_No_0_mean  = float(np.sum(data_High_No_0['response']==0))/len(data_High_No_0)\n",
    "data_acc_Low_Yes_1_mean  = float(np.sum(data_Low_Yes_1['response']==1))/len(data_Low_Yes_1)\n",
    "data_acc_Low_Yes_0_mean  = float(np.sum(data_Low_Yes_0['response']==0))/len(data_Low_Yes_0)\n",
    "data_acc_Low_No_1_mean   = float(np.sum(data_Low_No_1['response']==1))/len(data_Low_No_1)\n",
    "data_acc_Low_No_0_mean   = float(np.sum(data_Low_No_0['response']==0))/len(data_Low_No_0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#array mean rt\n",
    "data_rt_conds_mean = np.array([data_rt_High_Yes_1_mean,\n",
    "                               data_rt_High_Yes_0_mean,\n",
    "                               data_rt_High_No_1_mean,\n",
    "                               data_rt_High_No_0_mean,\n",
    "                               data_rt_Low_Yes_1_mean,\n",
    "                               data_rt_Low_Yes_0_mean,\n",
    "                               data_rt_Low_No_1_mean,\n",
    "                               data_rt_Low_No_0_mean])\n",
    "\n",
    "#array mean acc\n",
    "data_acc_conds_mean = np.array([data_acc_High_Yes_1_mean,\n",
    "                               data_acc_High_Yes_0_mean,\n",
    "                               data_acc_High_No_1_mean,\n",
    "                               data_acc_High_No_0_mean,\n",
    "                               data_acc_Low_Yes_1_mean,\n",
    "                               data_acc_Low_Yes_0_mean,\n",
    "                               data_acc_Low_No_1_mean,\n",
    "                               data_acc_Low_No_0_mean])\n",
    "\n",
    "\n",
    "\n",
    "print('r2_score rt:   ',  r2_score(data_rt_conds_mean, simulated_rt_cons_mean))\n",
    "print('r2_score acc:  ',  r2_score(data_acc_conds_mean, simulated_acc_cons_mean))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">> As you know, bayesian model estimation is stochastic and in each run you can see a bit defferent estimated parameters.\n",
    "If you want to run several times hDDM, you could choose one of them which you want\n",
    "I recommended you, it is worthwhile to chosse one whcih have better R_square score.\n",
    "So, after each run, you should simulate data from your model and use R-square model as goodness of fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plots of model convergence evaluation with the trace, auto-correlation, and histogram posterior distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelt = hddm.load('modelt') # load of modelt which is result of run_modelt function\n",
    "modelt.plot_posteriors()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plots of posterior parameters with histogram od data observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_6.plot_posteriors()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### R-hat values of modelt for four chin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kabuki.analyze import gelman_rubin\n",
    "modelst=[]\n",
    "for i in range(4):\n",
    "    m = models_utils.modelt(data)\n",
    "    modelst.append(m)\n",
    "gelman_rubin(modelst)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
